{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def calculate_accuracy(predicted_classes, actual_classes, ):\n",
    "    return sum(actual_classes[:] == predicted_classes[:]) / len(actual_classes)\n",
    "\n",
    "\n",
    "def generate_features_targets(data):\n",
    "    output_targets = np.empty(shape=(len(data)), dtype='<U20')\n",
    "    output_targets[:] = data['class']\n",
    "\n",
    "    input_features = np.empty(shape=(len(data), 13))\n",
    "    input_features[:, 0] = data['u-g']\n",
    "    input_features[:, 1] = data['g-r']\n",
    "    input_features[:, 2] = data['r-i']\n",
    "    input_features[:, 3] = data['i-z']\n",
    "    input_features[:, 4] = data['ecc']\n",
    "    input_features[:, 5] = data['m4_u']\n",
    "    input_features[:, 6] = data['m4_g']\n",
    "    input_features[:, 7] = data['m4_r']\n",
    "    input_features[:, 8] = data['m4_i']\n",
    "    input_features[:, 9] = data['m4_z']\n",
    "    input_features[:, 10] = data['petroR50_u'] / data['petroR90_u']\n",
    "    input_features[:, 11] = data['petroR50_r'] / data['petroR90_r']\n",
    "    input_features[:, 12] = data['petroR50_z'] / data['petroR90_z']\n",
    "\n",
    "    return input_features, output_targets\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    \n",
    "def rf_predict_actual(data, n_estimators):\n",
    "  # generate the features and targets\n",
    "  features, targets = generate_features_targets(data)\n",
    "\n",
    "  # instantiate a random forest classifier\n",
    "  rfc = RandomForestClassifier(n_estimators=n_estimators)\n",
    "  \n",
    "  # get predictions using 10-fold cross validation with cross_val_predict\n",
    "  predicted = cross_val_predict(rfc, features, targets, cv=10)\n",
    "\n",
    "  # return the predictions and their actual classes\n",
    "  return predicted, targets\n",
    "\n",
    "\n",
    "def initialize():\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "\n",
    "  # get the predicted and actual classes\n",
    "  number_estimators = 50              # Number of trees\n",
    "  predicted, actual = rf_predict_actual(data, number_estimators)\n",
    "\n",
    "  # calculate the model score using your function\n",
    "  accuracy = calculate_accuracy(predicted, actual)\n",
    "  print(\"Accuracy score:\", accuracy)\n",
    "\n",
    "  # calculate the models confusion matrix using sklearns confusion_matrix function\n",
    "  class_labels = list(set(actual))\n",
    "  model_cm = confusion_matrix(y_true=actual, y_pred=predicted, labels=class_labels)\n",
    "\n",
    "  # plot the confusion matrix using the provided functions.\n",
    "  plt.figure()\n",
    "  plot_confusion_matrix(model_cm, classes=class_labels, normalize=False)\n",
    "  plt.show()\n",
    "    \n",
    "def initial(fName):\n",
    "  data = np.load(fName)\n",
    "\n",
    "  # get the predicted and actual classes\n",
    "  number_estimators = 50              # Number of trees\n",
    "  predicted, actual = rf_predict_actual(data, number_estimators)\n",
    "\n",
    "  # calculate the model score using your function\n",
    "  accuracy = calculate_accuracy(predicted, actual)\n",
    "  print(\"Accuracy score:\", accuracy)\n",
    "\n",
    "  # calculate the models confusion matrix using sklearns confusion_matrix function\n",
    "  class_labels = list(set(actual))\n",
    "  model_cm = confusion_matrix(y_true=actual, y_pred=predicted, labels=class_labels)\n",
    "\n",
    "  # plot the confusion matrix using the provided functions.\n",
    "  plt.figure()\n",
    "  plot_confusion_matrix(model_cm, classes=class_labels, normalize=False)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
